# Sign & Speak - AI-powered Communication

<p align="center"><img src="img/sign-and-speak-logo-small.png" /></p>

## Project Overview

TODO

## Project Abstract

Sign & Speak facilitates communication between users of spoken language and users of sign language. By applying AI models trained to transcribe speech and interpret sign language, combined with a camera and a microphone, the tool enables two-way conversation in situations where communication was previously challenging.

## Participant Experience

TODO

## Architecture

TODO - describe architecture 

<p align="center"><img src="img/sign-and-speak-architecture.png" /></p>

## User Guide

TODO

### Machine Learning Model

TODO

#### Creating a data set

TODO

#### Training and deploying a model

TODO

### User Interface

TODO

## FAQ

TODO - Add more Q/A

**Q: There is more than one sign language?**

**A:** TODO

**Q: Will this method work for sign languages other than Auslan?**

**A:** TODO

**Q: Can you share your Auslan data set and/or model?**

**A:** TODO

**Q: What is the animal in your logo?**

**A:** TODO

## Authors

Sara 'Moose' van de Moosdijk, AWS ([GitHub](https://github.com/moose-in-australia/) | [LinkedIn](https://www.linkedin.com/in/saravandemoosdijk/))

Eshaan Anand, AWS (GitHub | LinkedIn)

## License

This library is licensed under the Apache 2.0 License.