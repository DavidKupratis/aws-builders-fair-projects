# Sign & Speak - AI-powered Communication

<div style="text-align:center"><img src="img/sign-and-speak-logo-small.png" /></div>

## Project Overview

TODO

## Project Abstract

Sign & Speak facilitates communication between users of spoken language and users of sign language. By applying AI models trained to transcribe speech and interpret sign language, combined with a camera and a microphone, the tool enables two-way conversation in situations where communication was previously challenging.

## Architecture

TODO

## User Guide

TODO

### Machine Learning Model

TODO

#### Creating a data set

TODO

#### Training and deploying a model

TODO

### User Interface

TODO

## FAQ

TODO - Add more Q/A

**Q: There is more than one sign language?**
**A:** TODO

**Q: Will this method work for sign languages other than Auslan?**
**A:** TODO

**Q: Can you share your Auslan data set and/or model?**
**A:** TODO

## Authors

Sara 'Moose' van de Moosdijk, AWS ([GitHub](https://github.com/moose-in-australia/) | [LinkedIn](https://www.linkedin.com/in/saravandemoosdijk/))
Eshaan Anand, AWS (GitHub | LinkedIn)

## License

This library is licensed under the Apache 2.0 License.